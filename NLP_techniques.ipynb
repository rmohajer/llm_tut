{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This document summarizes techniques for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is a popular technique used in natural language processing (NLP) to learn word embeddings, which are dense vector representations of words. These embeddings capture semantic relationships between words, enabling various NLP tasks like text classification, sentiment analysis, and machine translation.\n",
    "\n",
    "How Word2Vec Works:\n",
    "\n",
    "Word2Vec employs shallow neural networks to learn these embeddings through two main architectures:\n",
    "\n",
    "\t1.\tContinuous Bag of Words (CBOW)\n",
    "\t2.\tSkip-gram\n",
    "\n",
    "1. Continuous Bag of Words (CBOW):\n",
    "\n",
    "In the CBOW architecture, the model predicts the target word (center word) from the context words (surrounding words).\n",
    "\n",
    "Example:\n",
    "For the sentence “The quick brown fox jumps over the lazy dog”:\n",
    "\n",
    "\t•\tContext words: [“The”, “quick”, “brown”, “jumps”, “over”, “the”, “lazy”]\n",
    "\t•\tTarget word: “fox”\n",
    "\n",
    "CBOW uses these context words to predict the center word.\n",
    "\n",
    "2. Skip-gram:\n",
    "\n",
    "In the Skip-gram architecture, the model does the opposite: it uses the target word to predict the context words.\n",
    "\n",
    "Example:\n",
    "For the sentence “The quick brown fox jumps over the lazy dog”:\n",
    "\n",
    "\t•\tTarget word: “fox”\n",
    "\t•\tContext words: [“The”, “quick”, “brown”, “jumps”, “over”, “the”, “lazy”]\n",
    "\n",
    "Skip-gram uses the target word “fox” to predict the context words around it.\n",
    "\n",
    "Training Process:\n",
    "\n",
    "\t1.\tInput Layer:\n",
    "\t•\tThe input layer represents the words in a one-hot encoded format. Each word in the vocabulary is represented as a unique vector with a single high value (1) at the index corresponding to that word, and 0s elsewhere.\n",
    "\t2.\tHidden Layer:\n",
    "\t•\tThis layer consists of neurons where the dimensionality (number of neurons) is the size of the desired word embeddings. The one-hot encoded input vector is multiplied by the weight matrix (which is randomly initialized) to produce a dense vector representation.\n",
    "\t3.\tOutput Layer:\n",
    "\t•\tFor CBOW, the output layer uses softmax activation to predict the target word based on the context words. For Skip-gram, the model predicts context words given the target word.\n",
    "\t4.\tTraining Objective:\n",
    "\t•\tThe objective is to maximize the probability of predicting the correct context words (Skip-gram) or the target word (CBOW). The model is trained using stochastic gradient descent (SGD) to minimize the loss function (negative log-likelihood).\n",
    "\n",
    "Advantages of Word2Vec:\n",
    "\n",
    "\t1.\tEfficiency:\n",
    "\t•\tWord2Vec is computationally efficient and can be trained on large corpora of text data.\n",
    "\t2.\tSemantic Relationships:\n",
    "\t•\tThe learned word embeddings capture semantic relationships between words. Words with similar meanings are placed close to each other in the vector space.\n",
    "\t3.\tAnalogies:\n",
    "\t•\tWord2Vec embeddings can perform analogies. For example, the vector operation vector(\"king\") - vector(\"man\") + vector(\"woman\") results in a vector close to vector(\"queen\").\n",
    "\n",
    "Applications of Word2Vec:\n",
    "\n",
    "\t1.\tText Classification:\n",
    "\t•\tWord embeddings can be used as features for various text classification tasks such as sentiment analysis and spam detection.\n",
    "\t2.\tMachine Translation:\n",
    "\t•\tWord2Vec embeddings can improve the performance of machine translation systems by providing semantic understanding of words.\n",
    "\t3.\tInformation Retrieval:\n",
    "\t•\tWord embeddings can enhance information retrieval systems by improving the relevance of search results.\n",
    "\n",
    "Limitations:\n",
    "\n",
    "\t1.\tContext Limitations:\n",
    "\t•\tWord2Vec does not capture the meaning of words in different contexts. For example, “bank” (financial institution) and “bank” (river bank) have the same vector representation.\n",
    "\t2.\tGlobal Context:\n",
    "\t•\tWord2Vec focuses on local context (surrounding words) and does not consider the global context of the document.\n",
    "\n",
    "Despite these limitations, Word2Vec has been a foundational technique in NLP, leading to more advanced models like GloVe, FastText, and transformer-based models such as BERT and GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "# Sample text corpus\n",
    "text_corpus = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"The quick brown fox is quick and brown\",\n",
    "    \"The dog is lazy but the fox is quick\",\n",
    "    \"The dog and the fox are friends\",\n",
    "    \"Foxes are generally quick and clever\"\n",
    "]\n",
    "\n",
    "# Preprocess the text corpus (tokenization)\n",
    "processed_corpus = [simple_preprocess(doc) for doc in text_corpus]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=processed_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"models/word2vec.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'fox':\n",
      "[ 9.5206582e-05  3.0748248e-03 -6.8108444e-03 -1.3665740e-03\n",
      "  7.6626097e-03  7.3403954e-03 -3.6689078e-03  2.6489433e-03\n",
      " -8.3233844e-03  6.2000086e-03 -4.6304534e-03 -3.1658004e-03\n",
      "  9.3109543e-03  8.7781093e-04  7.4881148e-03 -6.0718209e-03\n",
      "  5.1674591e-03  9.9215815e-03 -8.4618432e-03 -5.1475419e-03\n",
      " -7.0607346e-03 -4.8577958e-03 -3.7723819e-03 -8.5381968e-03\n",
      "  7.9600606e-03 -4.8446902e-03  8.4199179e-03  5.2683153e-03\n",
      " -6.5555493e-03  3.9556306e-03  5.4700351e-03 -7.4236612e-03\n",
      " -7.3994389e-03 -2.4758563e-03 -8.6314492e-03 -1.5795515e-03\n",
      " -4.0072820e-04  3.2958947e-03  1.4387210e-03 -8.8398420e-04\n",
      " -5.5944361e-03  1.7337297e-03 -9.0112764e-04  6.7895600e-03\n",
      "  3.9761290e-03  4.5310068e-03  1.4260289e-03 -2.6959882e-03\n",
      " -4.3632290e-03 -1.0256181e-03  1.4318693e-03 -2.6435638e-03\n",
      " -7.0785210e-03 -7.8042592e-03 -9.1196662e-03 -5.9409705e-03\n",
      " -1.8487929e-03 -4.3292264e-03 -6.4616078e-03 -3.7139000e-03\n",
      "  4.2882790e-03 -3.7380953e-03  8.3818547e-03  1.5318182e-03\n",
      " -7.2463709e-03  9.4365850e-03  7.6255328e-03  5.4945918e-03\n",
      " -6.8525728e-03  5.8196886e-03  4.0132822e-03  5.1936978e-03\n",
      "  4.2540580e-03  1.9345561e-03 -3.1669531e-03  8.3512543e-03\n",
      "  9.6197473e-03  3.7911951e-03 -2.8375206e-03  3.2093933e-06\n",
      "  1.2197928e-03 -8.4593398e-03 -8.2240505e-03 -2.2263154e-04\n",
      "  1.2343475e-03 -5.7463115e-03 -4.7211084e-03 -7.3475209e-03\n",
      "  8.3298152e-03  1.2598652e-04 -4.5121587e-03  5.7045994e-03\n",
      "  9.1813048e-03 -4.0962761e-03  7.9736449e-03  5.3763734e-03\n",
      "  5.8749188e-03  5.0796830e-04  8.2178228e-03 -7.0155198e-03]\n",
      "Words most similar to 'fox':\n",
      "lazy: 0.1992\n",
      "foxes: 0.1728\n",
      "is: 0.1701\n",
      "brown: 0.1463\n",
      "dog: 0.0640\n",
      "Similarity between 'fox' and 'dog': 0.0640\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Word2Vec.load(\"models/word2vec.model\")\n",
    "\n",
    "# Find the word vector for a specific word\n",
    "word = \"fox\"\n",
    "word_vector = model.wv[word]\n",
    "print(f\"Vector for '{word}':\\n{word_vector}\")\n",
    "\n",
    "# Find the most similar words to a given word\n",
    "similar_words = model.wv.most_similar(word, topn=5)\n",
    "print(f\"Words most similar to '{word}':\")\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\"{similar_word}: {similarity:.4f}\")\n",
    "\n",
    "# Find the similarity between two words\n",
    "word1 = \"fox\"\n",
    "word2 = \"dog\"\n",
    "similarity = model.wv.similarity(word1, word2)\n",
    "print(f\"Similarity between '{word1}' and '{word2}': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec is an extension of Word2Vec designed to learn document-level embeddings, capturing the semantics of entire documents or paragraphs rather than just individual words. Introduced by Mikolov et al., the Doc2Vec algorithm enables the creation of fixed-length vectors for variable-length pieces of text, such as sentences, paragraphs, or documents.\n",
    "\n",
    "How Doc2Vec Works:\n",
    "\n",
    "Doc2Vec extends the Word2Vec technique by adding a unique vector for each document in addition to the vectors for each word. There are two main architectures for Doc2Vec:\n",
    "\n",
    "\t1.\tDistributed Memory Model of Paragraph Vectors (PV-DM):\n",
    "\t2.\tDistributed Bag of Words Model of Paragraph Vectors (PV-DBOW):\n",
    "\n",
    "1. Distributed Memory Model of Paragraph Vectors (PV-DM):\n",
    "\n",
    "\t•\tConcept:\n",
    "\t•\tThis architecture is similar to the Continuous Bag of Words (CBOW) model in Word2Vec.\n",
    "\t•\tIt predicts a target word based on the context words and the paragraph vector.\n",
    "\t•\tMechanism:\n",
    "\t•\tEach document is assigned a unique document vector.\n",
    "\t•\tFor a given context window, the context words and the document vector are combined to predict the target word.\n",
    "\t•\tExample:\n",
    "\t•\tFor the sentence “The quick brown fox jumps over the lazy dog” in a document D:\n",
    "\t•\tContext words: [“The”, “quick”, “brown”, “jumps”, “over”, “the”, “lazy”]\n",
    "\t•\tDocument vector: D\n",
    "\t•\tTarget word: “fox”\n",
    "\t•\tOutput:\n",
    "\t•\tThe document vector is trained alongside the word vectors to predict the target word.\n",
    "\n",
    "2. Distributed Bag of Words Model of Paragraph Vectors (PV-DBOW):\n",
    "\n",
    "\t•\tConcept:\n",
    "\t•\tThis architecture is analogous to the Skip-gram model in Word2Vec.\n",
    "\t•\tIt predicts the context words given a paragraph vector.\n",
    "\t•\tMechanism:\n",
    "\t•\tEach document is represented by a unique document vector.\n",
    "\t•\tThe model uses the document vector to predict words randomly sampled from the document.\n",
    "\t•\tExample:\n",
    "\t•\tFor the document D containing the sentence “The quick brown fox jumps over the lazy dog”:\n",
    "\t•\tDocument vector: D\n",
    "\t•\tTarget words: [“The”, “quick”, “brown”, “fox”, “jumps”, “over”, “the”, “lazy”, “dog”]\n",
    "\t•\tOutput:\n",
    "\t•\tThe document vector is trained to maximize the probability of observing the context words.\n",
    "\n",
    "Comparison to Word2Vec:\n",
    "\n",
    "\t1.\tGranularity:\n",
    "\t•\tWord2Vec: Learns embeddings for individual words.\n",
    "\t•\tDoc2Vec: Learns embeddings for entire documents, capturing the broader context of text.\n",
    "\t2.\tInput:\n",
    "\t•\tWord2Vec: Input is typically a corpus of individual words with their context.\n",
    "\t•\tDoc2Vec: Input includes both the words and unique document identifiers.\n",
    "\t3.\tUse Cases:\n",
    "\t•\tWord2Vec: Useful for tasks that require understanding of word-level semantics, such as word similarity and analogies.\n",
    "\t•\tDoc2Vec: Useful for tasks that require understanding of document-level semantics, such as document classification, clustering, and retrieval.\n",
    "\t4.\tTraining:\n",
    "\t•\tWord2Vec: Trains only on word context.\n",
    "\t•\tDoc2Vec: Trains on both word context and document context, leading to richer embeddings for longer pieces of text.\n",
    "\n",
    "Applications of Doc2Vec:\n",
    "\n",
    "\t1.\tDocument Classification:\n",
    "\t•\tDoc2Vec embeddings can be used as features for classifying documents into categories.\n",
    "\t2.\tInformation Retrieval:\n",
    "\t•\tEnhanced search and retrieval systems can be built using document embeddings to improve relevance and semantic matching.\n",
    "\t3.\tClustering:\n",
    "\t•\tDocuments can be clustered based on their embeddings to find similar documents or topics.\n",
    "\t4.\tRecommendation Systems:\n",
    "\t•\tDoc2Vec can be used to recommend documents based on their semantic similarity to user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Sample text corpus\n",
    "text_corpus = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"The quick brown fox is quick and brown\",\n",
    "    \"The dog is lazy but the fox is quick\",\n",
    "    \"The dog and the fox are friends\",\n",
    "    \"Foxes are generally quick and clever\"\n",
    "]\n",
    "\n",
    "# Tagging the documents\n",
    "tagged_data = [TaggedDocument(words=simple_preprocess(doc), tags=[str(i)]) for i, doc in enumerate(text_corpus)]\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "model = Doc2Vec(tagged_data, vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"models/doc2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for document 0:\n",
      "[-0.00548767 -0.00606968 -0.00995686  0.00874126  0.00358347  0.00015194\n",
      " -0.00989958 -0.00506836 -0.0098034   0.00205154  0.0028294   0.00460761\n",
      " -0.00438578 -0.00315834 -0.00298827 -0.00889576  0.0021737   0.00938424\n",
      " -0.00961717 -0.00347656 -0.0038539   0.00269193 -0.00563782  0.00284514\n",
      "  0.00574004 -0.00808646 -0.00854593 -0.01004269  0.0049507  -0.00931784\n",
      "  0.00593264  0.00686022 -0.00649119 -0.00452083 -0.00136603  0.00173594\n",
      " -0.00159671 -0.00877885 -0.00376666  0.0016333  -0.00196375 -0.00720308\n",
      "  0.00424931 -0.00871457  0.00267007 -0.00467211  0.00058795 -0.0020042\n",
      "  0.00538977 -0.00816679 -0.00228767 -0.00013615 -0.0067442  -0.00665037\n",
      " -0.00206879  0.00891308 -0.00125013  0.00366755 -0.00587882  0.00891151\n",
      "  0.00308048  0.00951148  0.0045699  -0.00426746  0.00228867 -0.00441369\n",
      "  0.00585632  0.0019565  -0.00242584 -0.00590712 -0.00819883 -0.00082308\n",
      " -0.00906522 -0.00925959 -0.00783015  0.00223489 -0.00650887 -0.00798035\n",
      "  0.00203345  0.00204026  0.00834649  0.00477422 -0.00964566 -0.00026807\n",
      "  0.00780453  0.00283567  0.00275762 -0.00501466  0.00648368  0.00169408\n",
      " -0.00783688  0.00696605 -0.00997927 -0.00826055 -0.00486486  0.01021749\n",
      "  0.00320019 -0.00202508  0.00912986  0.00239963]\n",
      "Documents most similar to document 0:\n",
      "Document 1: 0.1771\n",
      "Document 2: 0.0139\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Doc2Vec.load(\"models/doc2vec.model\")\n",
    "\n",
    "# Get the document vector for a specific document\n",
    "doc_id = \"0\"\n",
    "doc_vector = model.dv[doc_id]\n",
    "print(f\"Vector for document {doc_id}:\\n{doc_vector}\")\n",
    "\n",
    "# Find the most similar documents to a given document\n",
    "similar_docs = model.dv.most_similar(doc_id, topn=2)\n",
    "print(f\"Documents most similar to document {doc_id}:\")\n",
    "for similar_doc, similarity in similar_docs:\n",
    "    print(f\"Document {similar_doc}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Supervised Word2Vec\n",
    "\n",
    "Supervised Word2Vec extends the Word2Vec model by incorporating label information. This can be done by appending the target flag to the context window or using labeled data to guide the training process.\n",
    "\n",
    "Example:\n",
    "\n",
    "\t•\tIn a claim data sample, the word “stolen” appears in the context of claims labeled with “fraud.”\n",
    "\t•\tDuring training, the context window includes both the surrounding words and the label “fraud.”\n",
    "\n",
    "2. FastText with Supervision\n",
    "\n",
    "FastText is an extension of Word2Vec that considers subword information. By adding label information into the training process, FastText can capture relationships between words and labels.\n",
    "\n",
    "Implementation:\n",
    "\n",
    "\t•\tTrain FastText on sentences where each sentence includes the target flag as part of the context.\n",
    "\t•\tThis way, words that frequently appear with certain labels will have embeddings that capture this relationship.\n",
    "\n",
    "3. Label-Enhanced Document Embedding (LEDE)\n",
    "\n",
    "LEDE involves enhancing document embeddings with label information. This approach combines document-level embeddings with label information to produce vectors that capture both the content and the associated labels.\n",
    "\n",
    "Implementation:\n",
    "\n",
    "\t•\tUse Doc2Vec or another document embedding technique.\n",
    "\t•\tDuring training, include the label information as part of the input.\n",
    "\n",
    "4. Neural Network-Based Embeddings with Supervision\n",
    "\n",
    "Neural networks, such as recurrent neural networks (RNNs) or transformers, can be trained in a supervised manner to capture relationships between words and target flags.\n",
    "\n",
    "Example with Transformers:\n",
    "\n",
    "\t•\tTrain a transformer model (like BERT) on a dataset with labeled claims.\n",
    "\t•\tFine-tune the model to predict the target flag (e.g., “fraud”) based on the input text.\n",
    "\t•\tThe embeddings generated by the model will capture relationships between words and the target flag.\n",
    "\n",
    "5. Joint Embedding Models\n",
    "\n",
    "Joint embedding models train word embeddings and label embeddings simultaneously, ensuring that the learned vectors capture relationships between words and labels.\n",
    "\n",
    "Example:\n",
    "\n",
    "\t•\tA joint embedding model learns both word and label vectors in the same vector space.\n",
    "\t•\tWords like “stolen” will be close to the “fraud” label in this space if they frequently co-occur in labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for supervised word2vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Sample text corpus with labels\n",
    "text_corpus = [\n",
    "    (\"The quick brown fox jumps over the lazy dog\", \"normal\"),\n",
    "    (\"The quick brown fox is quick and brown\", \"normal\"),\n",
    "    (\"The dog is lazy but the fox is quick\", \"normal\"),\n",
    "    (\"The dog and the fox are friends\", \"normal\"),\n",
    "    (\"The wallet was stolen from the car\", \"fraud\"),\n",
    "    (\"Credit card fraud detected in the system\", \"fraud\"),\n",
    "    (\"vehicle claim is lodged within 2 days from policy inception\", \"fraud\")\n",
    "]\n",
    "\n",
    "# Preprocess the text corpus and append labels\n",
    "labeled_corpus = []\n",
    "for doc, label in text_corpus:\n",
    "    words = simple_preprocess(doc)\n",
    "    words.append(label)  # Append label as a word\n",
    "    labeled_corpus.append(words)\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=labeled_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"models/supervised_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'stolen':\n",
      "[ 5.6267120e-03  5.4973708e-03  1.8291199e-03  5.7494068e-03\n",
      " -8.9680776e-03  6.5593575e-03  9.2259916e-03 -4.2071473e-03\n",
      "  1.6075504e-03 -5.2338815e-03  1.0582185e-03  2.7701687e-03\n",
      "  8.1607364e-03  5.4401276e-04  2.5570584e-03  1.2977350e-03\n",
      "  8.4025227e-03 -5.7077026e-03 -6.2618302e-03 -3.6275184e-03\n",
      " -2.3005498e-03  5.0410628e-03 -8.1203571e-03 -2.8335357e-03\n",
      " -8.1974268e-03  5.1497100e-03 -2.5680638e-03 -9.0671070e-03\n",
      "  4.0717293e-03  9.0173231e-03 -3.0376601e-03 -5.8385395e-03\n",
      "  3.0198884e-03 -4.3584823e-04 -9.9794362e-03  8.4177041e-03\n",
      " -7.3388875e-03 -4.9304068e-03 -2.6570810e-03 -5.4523144e-03\n",
      "  1.7165100e-03  9.7128144e-03  4.5722723e-03  8.0886027e-03\n",
      " -4.7045827e-04  6.4492342e-04 -2.6683521e-03 -8.7795611e-03\n",
      "  3.4313034e-03  2.0933736e-03 -9.4218543e-03 -4.9684369e-03\n",
      " -9.7340988e-03 -5.7197916e-03  4.0645422e-03  8.6428607e-03\n",
      "  4.1116499e-03  2.3884643e-03  8.1447782e-03 -1.1192096e-03\n",
      " -1.3977134e-03 -8.7468233e-03 -1.2579202e-04 -2.5675725e-03\n",
      "  3.8607715e-04  7.2796619e-03 -7.0414604e-03 -3.9464748e-03\n",
      " -6.6646053e-03 -3.5441148e-03 -3.3158315e-03  2.1371210e-03\n",
      "  3.3281683e-03 -4.9571870e-03 -4.5462907e-03  1.1386942e-03\n",
      "  5.4534827e-03  5.3736498e-03 -2.9685367e-03 -4.2665256e-03\n",
      " -5.6166472e-03 -5.4498314e-04  1.9463730e-03  1.5253461e-03\n",
      "  7.3525296e-03 -2.7333724e-03 -6.5923930e-05 -5.5276332e-03\n",
      " -1.1700654e-03 -7.7119637e-03 -9.5932960e-04  1.3096749e-03\n",
      " -8.5947439e-03  8.7485835e-03 -9.2078662e-03 -9.6246768e-03\n",
      " -8.5116243e-03  7.3132683e-03  5.4655685e-03  9.2494618e-03]\n",
      "Words most similar to 'stolen':\n",
      "brown: 0.3190\n",
      "lodged: 0.1889\n",
      "but: 0.1621\n",
      "system: 0.1279\n",
      "dog: 0.1107\n",
      "Similarity between 'days' and 'fraud': 0.0066\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Word2Vec.load(\"models/supervised_word2vec.model\")\n",
    "\n",
    "# Find the word vector for a specific word\n",
    "word = \"stolen\"\n",
    "word_vector = model.wv[word]\n",
    "print(f\"Vector for '{word}':\\n{word_vector}\")\n",
    "\n",
    "# Find the most similar words to a given word\n",
    "similar_words = model.wv.most_similar(word, topn=5)\n",
    "print(f\"Words most similar to '{word}':\")\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\"{similar_word}: {similarity:.4f}\")\n",
    "\n",
    "# Find the similarity between a word and a label\n",
    "word1 = \"days\"\n",
    "label = \"fraud\"\n",
    "similarity = model.wv.similarity(word1, label)\n",
    "print(f\"Similarity between '{word1}' and '{label}': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis using CNN-LSTM and Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link to dataset:** 1,578,627 classified tweets, each row is marked as 1 for positive sentiment and 0 for negative sentiment from Twitter Sentiment Analysis Training Corpus (Dataset)\n",
    "[Link to the file](http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip)\n",
    "\n",
    "\n",
    "**Sentiment Analysis on Twitter Data using Word2Vec (gensim) in Keras**\n",
    "\n",
    "Sentiment Analysis refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine.[Source: Wikipedia]\n",
    "\n",
    "I attempt here to perform sentiment analysis using Word2Vec Text Embedding from gensim.\n",
    "\n",
    "The analysis and training is performed on 400,000 Tweets which are either Positive or Negative\n",
    "\n",
    "With training on 400,000 Tweets, using word2vec, I was able to achieve an accuracy of approximately 69%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('bigdata/SAD.csv',on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pos and neg tweets\n",
    "\n",
    "pos_df = df[df['Sentiment']==1]\n",
    "neg_df = df[df['Sentiment']==0]\n",
    "\n",
    "pos_tweets = pos_df['SentimentText']\n",
    "neg_tweets = neg_df['SentimentText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rezamohajerpoor/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling ..\n",
      "Generating Labels ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:00<00:00, 869784.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing ..\n",
      "Done.\n",
      "Lemmatizing ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:59<00:00, 6719.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "random.seed(1000)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z0-9]\\w+')\n",
    "\n",
    "\n",
    "pos_tweets = pos_tweets[:200000]\n",
    "neg_tweets = neg_tweets[:200000]\n",
    "  \n",
    "print('Shuffling ..')\n",
    "tweets_unclean = list(pos_tweets) + list(neg_tweets)\n",
    "random.shuffle(tweets_unclean)\n",
    "\n",
    "print('Generating Labels ..')\n",
    "labels = []\n",
    "\n",
    "with tqdm(total=len(tweets_unclean)) as pbar:\n",
    "    for tweet in tweets_unclean:\n",
    "        if tweet in pos_tweets:\n",
    "              labels.append(1)\n",
    "        else:\n",
    "              labels.append(0)\n",
    "\n",
    "        pbar.update(1)\n",
    "    \n",
    "del pos_tweets\n",
    "del neg_tweets\n",
    "\n",
    "print('Tokenizing ..')\n",
    "tweets = [tokenizer.tokenize(tweet.lower()) for tweet in tweets_unclean]\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "tweets = []\n",
    "\n",
    "print('Lemmatizing ..')\n",
    "\n",
    "with tqdm(total=len(tweets_unclean)) as pbar:\n",
    "    for tweet in tweets_unclean:\n",
    "        lemmatized = [lemmatizer.lemmatize(word) for word in tweet]\n",
    "        tweets.append(lemmatized)\n",
    "        pbar.update(1)\n",
    "\n",
    "del tweets_unclean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 150\n",
    "window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Word2Vec Vectors ..\n",
      "Word2Vec Created in 20.161959886550903 seconds.\n",
      "Word2Vec Model saved at models/w2v_sentiment.model\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import time\n",
    "\n",
    "word2vec_model = 'models/w2v_sentiment.model'\n",
    "\n",
    "print('Generating Word2Vec Vectors ..')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = Word2Vec(sentences=tweets, vector_size=vector_size, window=window, min_count=1, workers=4)\n",
    "\n",
    "print('Word2Vec Created in {} seconds.'.format(time.time() - start))\n",
    "\n",
    "model.save(word2vec_model)\n",
    "print('Word2Vec Model saved at {}'.format(word2vec_model))\n",
    "\n",
    "# Got to clear the memory!\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model!\n",
    "model = Word2Vec.load(word2vec_model)\n",
    "x_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 400000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels), len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning the dataset\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "train_size = int(0.9*(len(tweets)))\n",
    "test_size = int(0.1*(len(tweets)))\n",
    "\n",
    "max_no_tokens = 15\n",
    "\n",
    "indexes = set(np.random.choice(len(tweets), train_size + test_size, replace=False))\n",
    "\n",
    "x_train = np.zeros((train_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
    "y_train = np.zeros((train_size, 2), dtype=np.int32)\n",
    "\n",
    "x_test = np.zeros((test_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
    "y_test = np.zeros((test_size, 2), dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, index in enumerate(indexes):\n",
    "    for t, token in enumerate(tweets[index]):\n",
    "        if t >= max_no_tokens:\n",
    "            break\n",
    "      \n",
    "        if token not in x_vectors:\n",
    "            continue\n",
    "    \n",
    "        if i < train_size:\n",
    "            x_train[i, t, :] = x_vectors[token]\n",
    "        else:\n",
    "            x_test[i - train_size, t, :] = x_vectors[token]\n",
    "\n",
    "  \n",
    "    if i < train_size:\n",
    "        y_train[i, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
    "    else:\n",
    "        y_test[i - train_size, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360000, 15, 150), (40000, 2))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Neural Model\n",
    "\n",
    "For training a combination of Convolution Neural Network and Bidirectional Long Short Term Memory Network is used (CNN-LSTM).\n",
    "\n",
    "Batch Size is 100.\n",
    "\n",
    "To prevent overfitting or over training of the network, EarlyStopping() is used in callbacks thus if the network does not improve or starts overfitting, the training comes to an end.\n",
    "\n",
    "Acrhitecture of Network:\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "Conv1D -> Conv1D -> Conv1D -> Max Pooling1D -> Bidirectional LSTM -> Dense -> Dropout -> Dense -> Dropout -> Dense -> Dropout -> Output\n",
    "\n",
    "==============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "no_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,232,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m14,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,232,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,026\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,098</span> (12.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,304,098\u001b[0m (12.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,098</span> (12.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,304,098\u001b[0m (12.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same',\n",
    "                 input_shape=(max_no_tokens, vector_size)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "\n",
    "model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001, weight_decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 130ms/step - accuracy: 0.9814 - loss: 0.0397 - val_accuracy: 1.0000 - val_loss: 8.9229e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.1493e-04 - val_accuracy: 1.0000 - val_loss: 3.0124e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 4.4722e-05 - val_accuracy: 1.0000 - val_loss: 1.4678e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 2.3197e-05 - val_accuracy: 1.0000 - val_loss: 8.3542e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2df77cc90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=no_epochs,\n",
    "         validation_data=(x_test, y_test), callbacks=[tensorboard, EarlyStopping(min_delta=0.0001, patience=3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'compile_metrics']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.3535e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.354185411008075e-06, 1.0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/twitter-sentiment-word2vec-400k.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_tut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
